Renamed and copied: Case1021_image.nii.gz -> Case_1021_0000.nii.gz
All files renamed and copied.
using model stored in  /blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1
This model expects 1 input modalities for each image
Found 1 unique case ids, here are some examples: ['Case_1021']
If they don't look right, make sure to double check your filenames. They must end with _0000.nii.gz etc
/blue/joel.harley/charlietran/docker_care/mednext/nnunet_mednext/training/model_restore.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  all_params = [torch.load(i, map_location=torch.device('cpu')) for i in all_best_model_files]
number of cases: 1
number of cases that still need to be predicted: 1
emptying cuda cache
loading parameters for folds, None
folds is None so we will automatically look for output folders (not using 'all'!)
found the following folds:  ['/blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1/fold_0', '/blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1/fold_1', '/blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1/fold_2', '/blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1/fold_3', '/blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1/fold_4']
using the following model files:  ['/blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1/fold_0/model_final_checkpoint.model', '/blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1/fold_1/model_final_checkpoint.model', '/blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1/fold_2/model_final_checkpoint.model', '/blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1/fold_3/model_final_checkpoint.model', '/blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1/fold_4/model_final_checkpoint.model']
starting preprocessing generator
starting prediction...
preprocessing ../intermediate/test_pred/3d_M/Case_1021.nii.gz
using preprocessor GenericPreprocessor
before crop: (1, 256, 512, 512) after crop: (1, 256, 512, 512) spacing: [0.625      0.41992199 0.41992199] 

no separate z, order 3
no separate z, order 1
before: {'spacing': array([0.625     , 0.41992199, 0.41992199]), 'spacing_transposed': array([0.625     , 0.41992199, 0.41992199]), 'data.shape (data is transposed)': (1, 256, 512, 512)} 
after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 160, 215, 215)} 

(1, 160, 215, 215)
This worker has ended successfully, no errors to report
/blue/joel.harley/charlietran/docker_care/mednext/nnunet_mednext/training/network_training/network_trainer.py:404: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.amp_grad_scaler = GradScaler()
/home/charlietran/conda/envs/dockerwhs/lib/python3.12/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn(
/blue/joel.harley/charlietran/docker_care/mednext/nnunet_mednext/network_architecture/neural_network.py:141: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with context():
/home/charlietran/conda/envs/dockerwhs/lib/python3.12/site-packages/torch/amp/autocast_mode.py:265: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
  warnings.warn(
/home/charlietran/conda/envs/dockerwhs/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
predicting ../intermediate/test_pred/3d_M/Case_1021.nii.gz
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 160, 215, 215)
patch size: [128 128 128]
steps (x, y, and z): [[0, 32], [0, 44, 87], [0, 44, 87]]
number of tiles: 18
computing Gaussian
done
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 160, 215, 215)
patch size: [128 128 128]
steps (x, y, and z): [[0, 32], [0, 44, 87], [0, 44, 87]]
number of tiles: 18
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 160, 215, 215)
patch size: [128 128 128]
steps (x, y, and z): [[0, 32], [0, 44, 87], [0, 44, 87]]
number of tiles: 18
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 160, 215, 215)
patch size: [128 128 128]
steps (x, y, and z): [[0, 32], [0, 44, 87], [0, 44, 87]]
number of tiles: 18
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 160, 215, 215)
patch size: [128 128 128]
steps (x, y, and z): [[0, 32], [0, 44, 87], [0, 44, 87]]
number of tiles: 18
using precomputed Gaussian
prediction done
inference done. Now waiting for the segmentation export to finish...
postprocessing...
using model stored in  /blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M_DA5/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1
This model expects 1 input modalities for each image
Found 1 unique case ids, here are some examples: ['Case_1021']
If they don't look right, make sure to double check your filenames. They must end with _0000.nii.gz etc
/blue/joel.harley/charlietran/docker_care/mednext/nnunet_mednext/training/model_restore.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  all_params = [torch.load(i, map_location=torch.device('cpu')) for i in all_best_model_files]
number of cases: 1
number of cases that still need to be predicted: 1
emptying cuda cache
loading parameters for folds, None
folds is None so we will automatically look for output folders (not using 'all'!)
found the following folds:  ['/blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M_DA5/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1/fold_0', '/blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M_DA5/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1/fold_1', '/blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M_DA5/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1/fold_2', '/blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M_DA5/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1/fold_3', '/blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M_DA5/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1/fold_4']
using the following model files:  ['/blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M_DA5/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1/fold_0/model_final_checkpoint.model', '/blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M_DA5/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1/fold_1/model_final_checkpoint.model', '/blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M_DA5/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1/fold_2/model_final_checkpoint.model', '/blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M_DA5/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1/fold_3/model_final_checkpoint.model', '/blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M_DA5/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1/fold_4/model_final_checkpoint.model']
starting preprocessing generator
starting prediction...
preprocessing ../intermediate/test_pred/3d_M_DA5/Case_1021.nii.gz
using preprocessor GenericPreprocessor
before crop: (1, 256, 512, 512) after crop: (1, 256, 512, 512) spacing: [0.625      0.41992199 0.41992199] 

no separate z, order 3
no separate z, order 1
before: {'spacing': array([0.625     , 0.41992199, 0.41992199]), 'spacing_transposed': array([0.625     , 0.41992199, 0.41992199]), 'data.shape (data is transposed)': (1, 256, 512, 512)} 
after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 160, 215, 215)} 

(1, 160, 215, 215)
This worker has ended successfully, no errors to report
/blue/joel.harley/charlietran/docker_care/mednext/nnunet_mednext/training/network_training/network_trainer.py:404: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.amp_grad_scaler = GradScaler()
/home/charlietran/conda/envs/dockerwhs/lib/python3.12/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn(
/blue/joel.harley/charlietran/docker_care/mednext/nnunet_mednext/network_architecture/neural_network.py:141: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with context():
/home/charlietran/conda/envs/dockerwhs/lib/python3.12/site-packages/torch/amp/autocast_mode.py:265: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
  warnings.warn(
/home/charlietran/conda/envs/dockerwhs/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
predicting ../intermediate/test_pred/3d_M_DA5/Case_1021.nii.gz
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 160, 215, 215)
patch size: [128 128 128]
steps (x, y, and z): [[0, 32], [0, 44, 87], [0, 44, 87]]
number of tiles: 18
computing Gaussian
done
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 160, 215, 215)
patch size: [128 128 128]
steps (x, y, and z): [[0, 32], [0, 44, 87], [0, 44, 87]]
number of tiles: 18
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 160, 215, 215)
patch size: [128 128 128]
steps (x, y, and z): [[0, 32], [0, 44, 87], [0, 44, 87]]
number of tiles: 18
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 160, 215, 215)
patch size: [128 128 128]
steps (x, y, and z): [[0, 32], [0, 44, 87], [0, 44, 87]]
number of tiles: 18
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 160, 215, 215)
patch size: [128 128 128]
steps (x, y, and z): [[0, 32], [0, 44, 87], [0, 44, 87]]
number of tiles: 18
using precomputed Gaussian
prediction done
inference done. Now waiting for the segmentation export to finish...
postprocessing...
using model stored in  /blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M_DOMINO/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1
This model expects 1 input modalities for each image
Found 1 unique case ids, here are some examples: ['Case_1021']
If they don't look right, make sure to double check your filenames. They must end with _0000.nii.gz etc
/blue/joel.harley/charlietran/docker_care/mednext/nnunet_mednext/training/model_restore.py:153: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  all_params = [torch.load(i, map_location=torch.device('cpu')) for i in all_best_model_files]
number of cases: 1
number of cases that still need to be predicted: 1
emptying cuda cache
loading parameters for folds, None
folds is None so we will automatically look for output folders (not using 'all'!)
found the following folds:  ['/blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M_DOMINO/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1/fold_0', '/blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M_DOMINO/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1/fold_1', '/blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M_DOMINO/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1/fold_2', '/blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M_DOMINO/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1/fold_3', '/blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M_DOMINO/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1/fold_4']
using the following model files:  ['/blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M_DOMINO/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1/fold_0/model_final_checkpoint.model', '/blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M_DOMINO/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1/fold_1/model_final_checkpoint.model', '/blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M_DOMINO/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1/fold_2/model_final_checkpoint.model', '/blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M_DOMINO/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1/fold_3/model_final_checkpoint.model', '/blue/joel.harley/charlietran/docker_care/mednext/nnUNet_trained_models/nnUNet/3d_M_DOMINO/Task800_MedNXT/nnUNetTrainerV2_MedNeXt_M_kernel3__nnUNetPlansv2.1_trgSp_1x1x1/fold_4/model_final_checkpoint.model']
starting preprocessing generator
starting prediction...
preprocessing ../intermediate/test_pred/3d_M_DOMINO/Case_1021.nii.gz
using preprocessor GenericPreprocessor
before crop: (1, 256, 512, 512) after crop: (1, 256, 512, 512) spacing: [0.625      0.41992199 0.41992199] 

no separate z, order 3
no separate z, order 1
before: {'spacing': array([0.625     , 0.41992199, 0.41992199]), 'spacing_transposed': array([0.625     , 0.41992199, 0.41992199]), 'data.shape (data is transposed)': (1, 256, 512, 512)} 
after:  {'spacing': array([1., 1., 1.]), 'data.shape (data is resampled)': (1, 160, 215, 215)} 

(1, 160, 215, 215)
This worker has ended successfully, no errors to report
/blue/joel.harley/charlietran/docker_care/mednext/nnunet_mednext/training/network_training/network_trainer.py:404: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self.amp_grad_scaler = GradScaler()
/home/charlietran/conda/envs/dockerwhs/lib/python3.12/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn(
/blue/joel.harley/charlietran/docker_care/mednext/nnunet_mednext/network_architecture/neural_network.py:141: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with context():
/home/charlietran/conda/envs/dockerwhs/lib/python3.12/site-packages/torch/amp/autocast_mode.py:265: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
  warnings.warn(
/home/charlietran/conda/envs/dockerwhs/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
force_separate_z: None interpolation order: 1
separate z: False lowres axis None
no separate z, order 1
predicting ../intermediate/test_pred/3d_M_DOMINO/Case_1021.nii.gz
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 160, 215, 215)
patch size: [128 128 128]
steps (x, y, and z): [[0, 32], [0, 44, 87], [0, 44, 87]]
number of tiles: 18
computing Gaussian
done
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 160, 215, 215)
patch size: [128 128 128]
steps (x, y, and z): [[0, 32], [0, 44, 87], [0, 44, 87]]
number of tiles: 18
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 160, 215, 215)
patch size: [128 128 128]
steps (x, y, and z): [[0, 32], [0, 44, 87], [0, 44, 87]]
number of tiles: 18
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 160, 215, 215)
patch size: [128 128 128]
steps (x, y, and z): [[0, 32], [0, 44, 87], [0, 44, 87]]
number of tiles: 18
using precomputed Gaussian
prediction done
debug: mirroring True mirror_axes (0, 1, 2)
step_size: 0.5
do mirror: True
data shape: (1, 160, 215, 215)
patch size: [128 128 128]
steps (x, y, and z): [[0, 32], [0, 44, 87], [0, 44, 87]]
number of tiles: 18
using precomputed Gaussian
prediction done
inference done. Now waiting for the segmentation export to finish...
postprocessing...
force_separate_z: None interpolation order: 3
no resampling necessary
Postprocessing...
Moved Case_1021.nii.gz to ../intermediate/test_pred_reverse_name/Case1021_pred.nii.gz
Remapped file saved: Case1021_pred.nii.gz
